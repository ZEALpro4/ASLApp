{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUDA Environment Check ===\n",
      "Checking CUDA for PyTorch...\n",
      "PyTorch CUDA is available!\n",
      "PyTorch CUDA Version: 12.4\n",
      "Number of GPUs detected by PyTorch: 1\n",
      "GPU Device Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "def check_pytorch_cuda():\n",
    "    print(\"Checking CUDA for PyTorch...\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch CUDA is available!\")\n",
    "        print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"Number of GPUs detected by PyTorch: {torch.cuda.device_count()}\")\n",
    "        print(f\"GPU Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"CUDA is NOT available in PyTorch!\")\n",
    "\n",
    "def main():\n",
    "    print(\"=== CUDA Environment Check ===\")\n",
    "    check_pytorch_cuda()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "# Increase the pixel limit (for large images)\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None  # Disable the limit entirely\n",
    "\n",
    "# Continue with your image processing code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed IMG_20250227_103851 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103851.jpg with annotations\n",
      "Processed IMG_20250227_103853 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103853.jpg with annotations\n",
      "Processed IMG_20250227_103857 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103857.jpg with annotations\n",
      "Processed IMG_20250227_103859 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103859.jpg with annotations\n",
      "Processed IMG_20250227_103903 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103903.jpg with annotations\n",
      "Processed IMG_20250227_103905 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103905.jpg with annotations\n",
      "Processed IMG_20250227_103907 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103907.jpg with annotations\n",
      "Processed IMG_20250227_103909 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103909.jpg with annotations\n",
      "Processed IMG_20250227_103911 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103911.jpg with annotations\n",
      "Processed IMG_20250227_103912 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_103912.jpg with annotations\n",
      "Processed IMG_20250227_104008 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104008.jpg with annotations\n",
      "Processed IMG_20250227_104009 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104009.jpg with annotations\n",
      "Processed IMG_20250227_104013 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104013.jpg with annotations\n",
      "Processed IMG_20250227_104015 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104015.jpg with annotations\n",
      "Processed IMG_20250227_104016 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104016.jpg with annotations\n",
      "Processed IMG_20250227_104019 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104019.jpg with annotations\n",
      "Processed IMG_20250227_104021 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104021.jpg with annotations\n",
      "Processed IMG_20250227_104023 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104023.jpg with annotations\n",
      "Processed IMG_20250227_104038 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104038.jpg with annotations\n",
      "Processed IMG_20250227_104115 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104115.jpg with annotations\n",
      "Processed IMG_20250227_104129 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104129.jpg with annotations\n",
      "Processed IMG_20250227_104131 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104131.jpg with annotations\n",
      "Processed IMG_20250227_104136 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104136.jpg with annotations\n",
      "Processed IMG_20250227_104138 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104138.jpg with annotations\n",
      "Processed IMG_20250227_104139 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104139.jpg with annotations\n",
      "Processed IMG_20250227_104142 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104142.jpg with annotations\n",
      "Processed IMG_20250227_104146 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104146.jpg with annotations\n",
      "Processed IMG_20250227_104150 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104150.jpg with annotations\n",
      "Processed IMG_20250227_104154 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104154.jpg with annotations\n",
      "Processed IMG_20250227_104156 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104156.jpg with annotations\n",
      "Processed IMG_20250227_104355 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104355.jpg with annotations\n",
      "Processed IMG_20250227_104358 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104358.jpg with annotations\n",
      "Processed IMG_20250227_104359 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104359.jpg with annotations\n",
      "Processed IMG_20250227_104401 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104401.jpg with annotations\n",
      "Processed IMG_20250227_104405 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104405.jpg with annotations\n",
      "Processed IMG_20250227_104407 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104407.jpg with annotations\n",
      "Processed IMG_20250227_104409 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104409.jpg with annotations\n",
      "Processed IMG_20250227_104411 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104411.jpg with annotations\n",
      "Processed IMG_20250227_104413 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104413.jpg with annotations\n",
      "Processed IMG_20250227_104432 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104432.jpg with annotations\n",
      "Processed IMG_20250227_104452 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104452.jpg with annotations\n",
      "Processed IMG_20250227_104454 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104454.jpg with annotations\n",
      "Processed IMG_20250227_104455 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104455.jpg with annotations\n",
      "Processed IMG_20250227_104503 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104503.jpg with annotations\n",
      "Processed IMG_20250227_104505 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104505.jpg with annotations\n",
      "Processed IMG_20250227_104507 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104507.jpg with annotations\n",
      "Processed IMG_20250227_104508 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104508.jpg with annotations\n",
      "Processed IMG_20250227_104510 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104510.jpg with annotations\n",
      "Processed IMG_20250227_104530 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104530.jpg with annotations\n",
      "Processed IMG_20250227_104535 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104535.jpg with annotations\n",
      "Processed IMG_20250227_104711 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104711.jpg with annotations\n",
      "Processed IMG_20250227_104713 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104713.jpg with annotations\n",
      "Processed IMG_20250227_104715 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104715.jpg with annotations\n",
      "Processed IMG_20250227_104718 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104718.jpg with annotations\n",
      "Processed IMG_20250227_104720 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104720.jpg with annotations\n",
      "Processed IMG_20250227_104725 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104725.jpg with annotations\n",
      "Processed IMG_20250227_104728 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104728.jpg with annotations\n",
      "Processed IMG_20250227_104731 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104731.jpg with annotations\n",
      "Processed IMG_20250227_104745 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104745.jpg with annotations\n",
      "Processed IMG_20250227_104748 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_104748.jpg with annotations\n",
      "Processed IMG_20250227_105223 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105223.jpg with annotations\n",
      "Processed IMG_20250227_105226 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105226.jpg with annotations\n",
      "Processed IMG_20250227_105228 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105228.jpg with annotations\n",
      "Processed IMG_20250227_105232 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105232.jpg with annotations\n",
      "Processed IMG_20250227_105234 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105234.jpg with annotations\n",
      "Processed IMG_20250227_105236 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105236.jpg with annotations\n",
      "Processed IMG_20250227_105237 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105237.jpg with annotations\n",
      "Processed IMG_20250227_105239 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105239.jpg with annotations\n",
      "Processed IMG_20250227_105242 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105242.jpg with annotations\n",
      "Processed IMG_20250227_105245 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105245.jpg with annotations\n",
      "Processed IMG_20250227_105321 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105321.jpg with annotations\n",
      "Processed IMG_20250227_105325 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105325.jpg with annotations\n",
      "Processed IMG_20250227_105327 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105327.jpg with annotations\n",
      "Processed IMG_20250227_105328 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105328.jpg with annotations\n",
      "Processed IMG_20250227_105331 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105331.jpg with annotations\n",
      "Processed IMG_20250227_105333 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105333.jpg with annotations\n",
      "Processed IMG_20250227_105334 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105334.jpg with annotations\n",
      "Processed IMG_20250227_105336 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105336.jpg with annotations\n",
      "Processed IMG_20250227_105338 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105338.jpg with annotations\n",
      "Processed IMG_20250227_105340 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105340.jpg with annotations\n",
      "Processed IMG_20250227_105425 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105425.jpg with annotations\n",
      "Processed IMG_20250227_105427 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105427.jpg with annotations\n",
      "Processed IMG_20250227_105428 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105428.jpg with annotations\n",
      "Processed IMG_20250227_105430 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105430.jpg with annotations\n",
      "Processed IMG_20250227_105432 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105432.jpg with annotations\n",
      "Processed IMG_20250227_105434 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105434.jpg with annotations\n",
      "Processed IMG_20250227_105435 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105435.jpg with annotations\n",
      "Processed IMG_20250227_105438 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105438.jpg with annotations\n",
      "Processed IMG_20250227_105440 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105440.jpg with annotations\n",
      "Processed IMG_20250227_105442 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105442.jpg with annotations\n",
      "Processed IMG_20250227_105539 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105539.jpg with annotations\n",
      "Processed IMG_20250227_105541 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105541.jpg with annotations\n",
      "Processed IMG_20250227_105542 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105542.jpg with annotations\n",
      "Processed IMG_20250227_105546 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105546.jpg with annotations\n",
      "Processed IMG_20250227_105549 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105549.jpg with annotations\n",
      "Processed IMG_20250227_105552 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105552.jpg with annotations\n",
      "Processed IMG_20250227_105554 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105554.jpg with annotations\n",
      "Processed IMG_20250227_105609 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105609.jpg with annotations\n",
      "Processed IMG_20250227_105626 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105626.jpg with annotations\n",
      "Processed IMG_20250227_105629 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_105629.jpg with annotations\n",
      "Processed IMG_20250227_110849 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110849.jpg with annotations\n",
      "Processed IMG_20250227_110854 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110854.jpg with annotations\n",
      "Processed IMG_20250227_110856 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110856.jpg with annotations\n",
      "Processed IMG_20250227_110900 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110900.jpg with annotations\n",
      "Processed IMG_20250227_110910 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110910.jpg with annotations\n",
      "Processed IMG_20250227_110912 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110912.jpg with annotations\n",
      "Processed IMG_20250227_110915 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110915.jpg with annotations\n",
      "Processed IMG_20250227_110917 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110917.jpg with annotations\n",
      "Processed IMG_20250227_110918 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110918.jpg with annotations\n",
      "Processed IMG_20250227_110923 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_110923.jpg with annotations\n",
      "Processed IMG_20250227_111058 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111058.jpg with annotations\n",
      "Processed IMG_20250227_111100 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111100.jpg with annotations\n",
      "Processed IMG_20250227_111104 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111104.jpg with annotations\n",
      "Processed IMG_20250227_111110 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111110.jpg with annotations\n",
      "Processed IMG_20250227_111112 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111112.jpg with annotations\n",
      "Processed IMG_20250227_111114 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111114.jpg with annotations\n",
      "Processed IMG_20250227_111116 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111116.jpg with annotations\n",
      "Processed IMG_20250227_111118 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111118.jpg with annotations\n",
      "Processed IMG_20250227_111126 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111126.jpg with annotations\n",
      "Processed IMG_20250227_111206 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111206.jpg with annotations\n",
      "Processed IMG_20250227_111250 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111250.jpg with annotations\n",
      "Processed IMG_20250227_111251 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111251.jpg with annotations\n",
      "Processed IMG_20250227_111255 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111255.jpg with annotations\n",
      "Processed IMG_20250227_111256 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111256.jpg with annotations\n",
      "Processed IMG_20250227_111259 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111259.jpg with annotations\n",
      "Processed IMG_20250227_111301 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111301.jpg with annotations\n",
      "Processed IMG_20250227_111303 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111303.jpg with annotations\n",
      "Processed IMG_20250227_111305 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111305.jpg with annotations\n",
      "Processed IMG_20250227_111325 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111325.jpg with annotations\n",
      "Processed IMG_20250227_111326 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111326.jpg with annotations\n",
      "Processed IMG_20250227_111446 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111446.jpg with annotations\n",
      "Processed IMG_20250227_111449 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111449.jpg with annotations\n",
      "Processed IMG_20250227_111455 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111455.jpg with annotations\n",
      "Processed IMG_20250227_111505 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111505.jpg with annotations\n",
      "Processed IMG_20250227_111508 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111508.jpg with annotations\n",
      "Processed IMG_20250227_111510 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111510.jpg with annotations\n",
      "Processed IMG_20250227_111512 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111512.jpg with annotations\n",
      "Processed IMG_20250227_111514 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111514.jpg with annotations\n",
      "Processed IMG_20250227_111515 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111515.jpg with annotations\n",
      "Processed IMG_20250227_111537 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111537.jpg with annotations\n",
      "Processed IMG_20250227_111548 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111548.jpg with annotations\n",
      "Processed IMG_20250227_111550 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111550.jpg with annotations\n",
      "Processed IMG_20250227_111552 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111552.jpg with annotations\n",
      "Processed IMG_20250227_111553 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111553.jpg with annotations\n",
      "Processed IMG_20250227_111557 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111557.jpg with annotations\n",
      "Processed IMG_20250227_111559 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111559.jpg with annotations\n",
      "Processed IMG_20250227_111601 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111601.jpg with annotations\n",
      "Processed IMG_20250227_111603 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111603.jpg with annotations\n",
      "Processed IMG_20250227_111604 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111604.jpg with annotations\n",
      "Processed IMG_20250227_111606 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111606.jpg with annotations\n",
      "Processed IMG_20250227_111858 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111858.jpg with annotations\n",
      "Processed IMG_20250227_111900 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111900.jpg with annotations\n",
      "Processed IMG_20250227_111901 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111901.jpg with annotations\n",
      "Processed IMG_20250227_111902 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111902.jpg with annotations\n",
      "Processed IMG_20250227_111903 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111903.jpg with annotations\n",
      "Processed IMG_20250227_111914 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111914.jpg with annotations\n",
      "Processed IMG_20250227_111917 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111917.jpg with annotations\n",
      "Processed IMG_20250227_111918 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111918.jpg with annotations\n",
      "Processed IMG_20250227_111920 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111920.jpg with annotations\n",
      "Processed IMG_20250227_111922 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_111922.jpg with annotations\n",
      "Processed IMG_20250227_112045 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112045.jpg with annotations\n",
      "Processed IMG_20250227_112047 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112047.jpg with annotations\n",
      "Processed IMG_20250227_112048 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112048.jpg with annotations\n",
      "Processed IMG_20250227_112050 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112050.jpg with annotations\n",
      "Processed IMG_20250227_112053 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112053.jpg with annotations\n",
      "Processed IMG_20250227_112054 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112054.jpg with annotations\n",
      "Processed IMG_20250227_112056 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112056.jpg with annotations\n",
      "Processed IMG_20250227_112057 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112057.jpg with annotations\n",
      "Processed IMG_20250227_112058 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112058.jpg with annotations\n",
      "Processed IMG_20250227_112100 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112100.jpg with annotations\n",
      "Processed IMG_20250227_112204 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112204.jpg with annotations\n",
      "Processed IMG_20250227_112205 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112205.jpg with annotations\n",
      "Processed IMG_20250227_112208 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112208.jpg with annotations\n",
      "Processed IMG_20250227_112210 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112210.jpg with annotations\n",
      "Processed IMG_20250227_112214 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112214.jpg with annotations\n",
      "Processed IMG_20250227_112217 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112217.jpg with annotations\n",
      "Processed IMG_20250227_112220 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112220.jpg with annotations\n",
      "Processed IMG_20250227_112221 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112221.jpg with annotations\n",
      "Processed IMG_20250227_112223 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112223.jpg with annotations\n",
      "Processed IMG_20250227_112237 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112237.jpg with annotations\n",
      "Processed IMG_20250227_112620 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112620.jpg with annotations\n",
      "Processed IMG_20250227_112626 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112626.jpg with annotations\n",
      "Processed IMG_20250227_112631 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112631.jpg with annotations\n",
      "Processed IMG_20250227_112633 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112633.jpg with annotations\n",
      "Processed IMG_20250227_112635 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112635.jpg with annotations\n",
      "Processed IMG_20250227_112637 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112637.jpg with annotations\n",
      "Processed IMG_20250227_112639 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112639.jpg with annotations\n",
      "Processed IMG_20250227_112658 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112658.jpg with annotations\n",
      "Processed IMG_20250227_112700 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112700.jpg with annotations\n",
      "Processed IMG_20250227_112702 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112702.jpg with annotations\n",
      "Processed IMG_20250227_112742 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112742.jpg with annotations\n",
      "Processed IMG_20250227_112747 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112747.jpg with annotations\n",
      "Processed IMG_20250227_112749 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112749.jpg with annotations\n",
      "Processed IMG_20250227_112750 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112750.jpg with annotations\n",
      "Processed IMG_20250227_112753 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112753.jpg with annotations\n",
      "Processed IMG_20250227_112755 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112755.jpg with annotations\n",
      "Processed IMG_20250227_112757 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112757.jpg with annotations\n",
      "Processed IMG_20250227_112759 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112759.jpg with annotations\n",
      "Processed IMG_20250227_112816 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112816.jpg with annotations\n",
      "Processed IMG_20250227_112818 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112818.jpg with annotations\n",
      "Processed IMG_20250227_112825 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112825.jpg with annotations\n",
      "Processed IMG_20250227_112828 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112828.jpg with annotations\n",
      "Processed IMG_20250227_112834 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112834.jpg with annotations\n",
      "Processed IMG_20250227_112836 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112836.jpg with annotations\n",
      "Processed IMG_20250227_112844 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112844.jpg with annotations\n",
      "Processed IMG_20250227_112846 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112846.jpg with annotations\n",
      "Processed IMG_20250227_112858 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112858.jpg with annotations\n",
      "Processed IMG_20250227_112903 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112903.jpg with annotations\n",
      "Processed IMG_20250227_112921 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112921.jpg with annotations\n",
      "Processed IMG_20250227_112930 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_112930.jpg with annotations\n",
      "Processed IMG_20250227_113212 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113212.jpg with annotations\n",
      "Processed IMG_20250227_113213 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113213.jpg with annotations\n",
      "Processed IMG_20250227_113216 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113216.jpg with annotations\n",
      "Processed IMG_20250227_113218 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113218.jpg with annotations\n",
      "Processed IMG_20250227_113220 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113220.jpg with annotations\n",
      "Processed IMG_20250227_113222 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113222.jpg with annotations\n",
      "Processed IMG_20250227_113224 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113224.jpg with annotations\n",
      "Processed IMG_20250227_113226 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113226.jpg with annotations\n",
      "Processed IMG_20250227_113228 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113228.jpg with annotations\n",
      "Processed IMG_20250227_113229 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113229.jpg with annotations\n",
      "Processed IMG_20250227_113320 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113320.jpg with annotations\n",
      "Processed IMG_20250227_113322 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113322.jpg with annotations\n",
      "Processed IMG_20250227_113328 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113328.jpg with annotations\n",
      "Processed IMG_20250227_113333 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113333.jpg with annotations\n",
      "Processed IMG_20250227_113335 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113335.jpg with annotations\n",
      "Processed IMG_20250227_113336 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113336.jpg with annotations\n",
      "Processed IMG_20250227_113338 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113338.jpg with annotations\n",
      "Processed IMG_20250227_113339 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113339.jpg with annotations\n",
      "Processed IMG_20250227_113341 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113341.jpg with annotations\n",
      "Processed IMG_20250227_113342 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113342.jpg with annotations\n",
      "Processed IMG_20250227_113437 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113437.jpg with annotations\n",
      "Processed IMG_20250227_113438 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113438.jpg with annotations\n",
      "Processed IMG_20250227_113447 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113447.jpg with annotations\n",
      "Processed IMG_20250227_113449 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113449.jpg with annotations\n",
      "Processed IMG_20250227_113451 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113451.jpg with annotations\n",
      "Processed IMG_20250227_113452 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113452.jpg with annotations\n",
      "Processed IMG_20250227_113454 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113454.jpg with annotations\n",
      "Processed IMG_20250227_113456 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113456.jpg with annotations\n",
      "Processed IMG_20250227_113510 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113510.jpg with annotations\n",
      "Processed IMG_20250227_113512 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_113512.jpg with annotations\n",
      "Processed IMG_20250227_114304 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114304.jpg with annotations\n",
      "Processed IMG_20250227_114307 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114307.jpg with annotations\n",
      "Processed IMG_20250227_114309 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114309.jpg with annotations\n",
      "Processed IMG_20250227_114312 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114312.jpg with annotations\n",
      "Processed IMG_20250227_114314 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114314.jpg with annotations\n",
      "Processed IMG_20250227_114318 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114318.jpg with annotations\n",
      "Processed IMG_20250227_114319 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114319.jpg with annotations\n",
      "Processed IMG_20250227_114321 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114321.jpg with annotations\n",
      "Processed IMG_20250227_114322 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114322.jpg with annotations\n",
      "Processed IMG_20250227_114324 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114324.jpg with annotations\n",
      "Processed IMG_20250227_114345 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114345.jpg with annotations\n",
      "Processed IMG_20250227_114347 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114347.jpg with annotations\n",
      "Processed IMG_20250227_114349 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114349.jpg with annotations\n",
      "Processed IMG_20250227_114351 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114351.jpg with annotations\n",
      "Processed IMG_20250227_114353 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114353.jpg with annotations\n",
      "Processed IMG_20250227_114356 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114356.jpg with annotations\n",
      "Processed IMG_20250227_114357 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114357.jpg with annotations\n",
      "Processed IMG_20250227_114359 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114359.jpg with annotations\n",
      "Processed IMG_20250227_114401 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114401.jpg with annotations\n",
      "Processed IMG_20250227_114403 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114403.jpg with annotations\n",
      "Processed IMG_20250227_114413 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114413.jpg with annotations\n",
      "Processed IMG_20250227_114415 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114415.jpg with annotations\n",
      "Processed IMG_20250227_114423 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114423.jpg with annotations\n",
      "Processed IMG_20250227_114425 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114425.jpg with annotations\n",
      "Processed IMG_20250227_114428 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114428.jpg with annotations\n",
      "Processed IMG_20250227_114431 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114431.jpg with annotations\n",
      "Processed IMG_20250227_114453 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114453.jpg with annotations\n",
      "Processed IMG_20250227_114502 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114502.jpg with annotations\n",
      "Processed IMG_20250227_114516 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114516.jpg with annotations\n",
      "Processed IMG_20250227_114519 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_114519.jpg with annotations\n",
      "Processed IMG_20250227_115128 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115128.jpg with annotations\n",
      "Processed IMG_20250227_115132 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115132.jpg with annotations\n",
      "Processed IMG_20250227_115134 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115134.jpg with annotations\n",
      "Processed IMG_20250227_115138 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115138.jpg with annotations\n",
      "Processed IMG_20250227_115139 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115139.jpg with annotations\n",
      "Processed IMG_20250227_115141 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115141.jpg with annotations\n",
      "Processed IMG_20250227_115146 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115146.jpg with annotations\n",
      "Processed IMG_20250227_115148 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115148.jpg with annotations\n",
      "Processed IMG_20250227_115150 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115150.jpg with annotations\n",
      "Processed IMG_20250227_115207 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115207.jpg with annotations\n",
      "Processed IMG_20250227_115236 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115236.jpg with annotations\n",
      "Processed IMG_20250227_115239 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115239.jpg with annotations\n",
      "Processed IMG_20250227_115241 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115241.jpg with annotations\n",
      "Processed IMG_20250227_115243 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115243.jpg with annotations\n",
      "Processed IMG_20250227_115245 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115245.jpg with annotations\n",
      "Processed IMG_20250227_115248 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115248.jpg with annotations\n",
      "Processed IMG_20250227_115250 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115250.jpg with annotations\n",
      "Processed IMG_20250227_115252 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115252.jpg with annotations\n",
      "Processed IMG_20250227_115257 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115257.jpg with annotations\n",
      "Processed IMG_20250227_115300 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115300.jpg with annotations\n",
      "Processed IMG_20250227_115328 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115328.jpg with annotations\n",
      "Processed IMG_20250227_115330 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115330.jpg with annotations\n",
      "Processed IMG_20250227_115332 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115332.jpg with annotations\n",
      "Processed IMG_20250227_115334 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115334.jpg with annotations\n",
      "Processed IMG_20250227_115336 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115336.jpg with annotations\n",
      "Processed IMG_20250227_115338 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115338.jpg with annotations\n",
      "Processed IMG_20250227_115344 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115344.jpg with annotations\n",
      "Processed IMG_20250227_115346 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115346.jpg with annotations\n",
      "Processed IMG_20250227_115347 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115347.jpg with annotations\n",
      "Processed IMG_20250227_115349 - Copy.jpg with annotations\n",
      "Processed IMG_20250227_115349.jpg with annotations\n",
      "All images and labels processed and saved in: resized_dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define paths and parameters\n",
    "input_folder = r\"dataset - Copy\"  # Folder containing original images and labels\n",
    "output_folder = r\"resized_dataset\"  # Folder to save resized images and labels together\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define new size for resizing images\n",
    "new_width = 600  # target width\n",
    "new_height = 800  # target height\n",
    "\n",
    "def read_yolo_labels(label_path, img_width, img_height):\n",
    "    \"\"\"Read YOLO format label file and convert to pixel coordinates.\"\"\"\n",
    "    bboxes = []\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x_center *= img_width\n",
    "                    y_center *= img_height\n",
    "                    width *= img_width\n",
    "                    height *= img_height\n",
    "                    x_min = x_center - width/2\n",
    "                    y_min = y_center - height/2\n",
    "                    x_max = x_center + width/2\n",
    "                    y_max = y_center + height/2\n",
    "                    bboxes.append([x_min, y_min, x_max, y_max])\n",
    "    return bboxes\n",
    "\n",
    "def draw_bounding_boxes(ax, image, bboxes, color='r'):\n",
    "    \"\"\"Draw bounding boxes on the given axis.\"\"\"\n",
    "    ax.imshow(image)\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "def process_image_and_labels(image_name, image_path, output_folder):\n",
    "    \"\"\"Process a single image and its corresponding labels.\"\"\"\n",
    "    try:\n",
    "        # Open and get original image dimensions\n",
    "        image = Image.open(image_path)\n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        # Calculate scaling factors\n",
    "        scale_x = new_width / original_width\n",
    "        scale_y = new_height / original_height\n",
    "        \n",
    "        # Resize the image\n",
    "        resized_image = image.resize((new_width, new_height))\n",
    "        \n",
    "        # Save the resized image\n",
    "        resized_image_path = os.path.join(output_folder, f\"resized_{image_name}\")\n",
    "        resized_image.save(resized_image_path)\n",
    "        \n",
    "        # Check for corresponding label file\n",
    "        base_name = os.path.splitext(image_name)[0]\n",
    "        label_file = f\"{base_name}.txt\"\n",
    "        label_path = os.path.join(input_folder, label_file)\n",
    "        \n",
    "        # Read original annotations\n",
    "        original_bboxes = read_yolo_labels(label_path, original_width, original_height)\n",
    "        \n",
    "        if original_bboxes:\n",
    "            adjusted_annotations = []\n",
    "            label_content = \"\"\n",
    "            \n",
    "            for bbox in original_bboxes:\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                # Adjust bounding box coordinates\n",
    "                new_bbox = [\n",
    "                    int(x_min * scale_x),\n",
    "                    int(y_min * scale_y),\n",
    "                    int(x_max * scale_x),\n",
    "                    int(y_max * scale_y)\n",
    "                ]\n",
    "                adjusted_annotations.append(new_bbox)\n",
    "                \n",
    "                # Convert back to YOLO format (normalized center coordinates and dimensions)\n",
    "                norm_x_center = ((new_bbox[0] + new_bbox[2]) / 2) / new_width\n",
    "                norm_y_center = ((new_bbox[1] + new_bbox[3]) / 2) / new_height\n",
    "                norm_width = (new_bbox[2] - new_bbox[0]) / new_width\n",
    "                norm_height = (new_bbox[3] - new_bbox[1]) / new_height\n",
    "                \n",
    "                # Add to label content (class 0 assumed - change if needed)\n",
    "                label_content += f\"0 {norm_x_center:.6f} {norm_y_center:.6f} {norm_width:.6f} {norm_height:.6f}\\n\"\n",
    "            \n",
    "            # Save the new label file\n",
    "            new_label_file = os.path.join(output_folder, f\"resized_{base_name}.txt\")\n",
    "            with open(new_label_file, 'w') as f:\n",
    "                f.write(label_content)\n",
    "            \n",
    "            # Create comparison visualization - only for the first few images to prevent crashes\n",
    "            if len(os.listdir(output_folder)) < 10:  # Only create comparisons for first 10 images\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "                axes[0].set_title(\"Original Image with BBox\")\n",
    "                draw_bounding_boxes(axes[0], image, original_bboxes, color='b')\n",
    "                \n",
    "                axes[1].set_title(\"Resized Image with Adjusted BBox\")\n",
    "                draw_bounding_boxes(axes[1], resized_image, adjusted_annotations, color='r')\n",
    "                \n",
    "                for ax in axes:\n",
    "                    ax.axis('off')\n",
    "                \n",
    "                comparison_path = os.path.join(output_folder, f\"comparison_{base_name}.png\")\n",
    "                plt.savefig(comparison_path, bbox_inches='tight')\n",
    "                plt.close(fig)  # Explicitly close the figure to free memory\n",
    "            \n",
    "            print(f\"Processed {image_name} with annotations\")\n",
    "        else:\n",
    "            print(f\"Processed {image_name} (no annotations found)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {str(e)}\")\n",
    "\n",
    "# Process all images in the input folder\n",
    "for image_name in sorted(os.listdir(input_folder)):\n",
    "    if image_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        process_image_and_labels(image_name, image_path, output_folder)\n",
    "\n",
    "print(\"All images and labels processed and saved in:\", output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split and copied successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "dataset_path = r\"/mnt/e/_clgproject/new_project/dataset - Copy\"  # Change this to your dataset folder\n",
    "output_dir = r\"/mnt/e/_clgproject/new_project/Yolov11_1\"  # Change this to your desired output location\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Get all image files (assuming they're .jpg, adjust if needed)\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith(\".jpg\")]\n",
    "random.shuffle(image_files)  # Shuffle to ensure randomness\n",
    "\n",
    "# Calculate split sizes\n",
    "num_images = len(image_files)\n",
    "train_count = int(num_images * train_ratio)\n",
    "val_count = int(num_images * val_ratio)\n",
    "test_count = num_images - train_count - val_count  # Remaining for test\n",
    "\n",
    "# Split the data\n",
    "train_files = image_files[:train_count]\n",
    "val_files = image_files[train_count:train_count + val_count]\n",
    "test_files = image_files[train_count + val_count:]\n",
    "\n",
    "# Function to copy images and labels\n",
    "def copy_files(file_list, split_name):\n",
    "    img_dest = os.path.join(output_dir, \"images\", split_name)\n",
    "    lbl_dest = os.path.join(output_dir, \"labels\", split_name)\n",
    "    os.makedirs(img_dest, exist_ok=True)\n",
    "    os.makedirs(lbl_dest, exist_ok=True)\n",
    "\n",
    "    for file in file_list:\n",
    "        img_src = os.path.join(dataset_path, file)\n",
    "        lbl_src = os.path.join(dataset_path, file.replace(\".jpg\", \".txt\"))  # Assuming YOLO format\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(img_src, os.path.join(img_dest, file))\n",
    "\n",
    "        # Copy annotation if exists\n",
    "        if os.path.exists(lbl_src):\n",
    "            shutil.copy2(lbl_src, os.path.join(lbl_dest, file.replace(\".jpg\", \".txt\")))\n",
    "\n",
    "# Copy files to respective folders\n",
    "copy_files(train_files, \"train\")\n",
    "copy_files(val_files, \"val\")\n",
    "copy_files(test_files, \"test\")\n",
    "\n",
    "print(\"Dataset split and copied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUDA Environment Check ===\n",
      "Checking CUDA for PyTorch...\n",
      "PyTorch CUDA is available!\n",
      "PyTorch CUDA Version: 12.4\n",
      "Number of GPUs detected by PyTorch: 1\n",
      "GPU Device Name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Ultralytics 8.3.97  Python-3.10.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/mnt/e/_clgproject/new_project/yolo11l.pt, data=/mnt/e/_clgproject/new_project/V8_final_dataset/V8_final_dataset/data.yaml, epochs=25, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=2, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1418734  ultralytics.nn.modules.head.Detect           [10, [256, 512, 512]]         \n",
      "YOLO11l summary: 357 layers, 25,318,190 parameters, 25,318,174 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/e/_clgproject/new_project/V8_final_dataset/V8_final_dataset/labels/train.cache... 420 images, 0 backgrounds, 0 corrupt: 100%|| 420/420 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/e/_clgproject/new_project/V8_final_dataset/V8_final_dataset/labels/val.cache... 120 images, 0 backgrounds, 0 corrupt: 100%|| 120/120 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25       5.6G      1.946      3.752      2.225          7        640: 100%|| 105/105 [02:59<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:21<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.511       0.53      0.556      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      5.77G      1.922      2.554      2.097          9        640: 100%|| 105/105 [02:40<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:14<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120       0.63      0.582      0.638      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      5.75G      1.936      2.421      2.124          9        640: 100%|| 105/105 [02:39<00:00,  1.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:22<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.781      0.476      0.694      0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      5.76G      1.872      2.491      2.137          8        640: 100%|| 105/105 [02:27<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:25<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.653      0.638      0.755      0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      5.71G      1.934      2.042      2.198          8        640: 100%|| 105/105 [02:45<00:00,  1.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:22<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.677      0.774      0.775      0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      5.75G      1.915      1.838      2.126          8        640: 100%|| 105/105 [02:47<00:00,  1.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:14<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.697       0.77      0.857      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      5.74G       1.83      1.739      2.113         11        640: 100%|| 105/105 [02:35<00:00,  1.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:24<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.822      0.787      0.926      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      5.76G      1.849      1.684      2.043          3        640: 100%|| 105/105 [02:33<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:17<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.759       0.89       0.91       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      5.74G      1.837      1.584      2.107          4        640: 100%|| 105/105 [02:29<00:00,  1.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:25<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.781      0.875      0.931      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      5.76G      1.801      1.487      2.004         10        640: 100%|| 105/105 [02:30<00:00,  1.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:16<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.798       0.91      0.933      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      5.74G      1.779      1.361      2.007          5        640: 100%|| 105/105 [02:33<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:25<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.818      0.919      0.936      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      5.76G      1.763      1.465      1.999         12        640: 100%|| 105/105 [02:31<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:17<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.872      0.893      0.911      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      5.74G      1.776      1.385      2.034          7        640: 100%|| 105/105 [02:36<00:00,  1.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:23<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.898       0.84      0.959      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      5.76G      1.674      1.278      2.002         11        640: 100%|| 105/105 [02:31<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:22<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.849       0.92      0.919      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25      5.74G      1.712      1.274      1.998         12        640: 100%|| 105/105 [02:33<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:24<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120       0.91      0.926      0.936      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      5.75G      1.652      0.972      2.084          4        640: 100%|| 105/105 [02:52<00:00,  1.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:18<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.964      0.951      0.976      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      5.74G       1.62     0.9149      2.079          4        640: 100%|| 105/105 [02:52<00:00,  1.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:23<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.948      0.958       0.99      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      5.76G      1.582     0.9029      2.038          4        640: 100%|| 105/105 [02:31<00:00,  1.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:17<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120       0.89      0.973      0.986      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      5.75G       1.52     0.8357      1.969          4        640: 100%|| 105/105 [02:33<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:23<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.951       0.96      0.989      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      5.75G      1.538     0.8021      1.989          4        640: 100%|| 105/105 [02:30<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.907      0.965       0.98       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25       5.7G      1.527     0.7858      1.983          4        640: 100%|| 105/105 [02:29<00:00,  1.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:22<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.891      0.964      0.984      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      5.75G      1.507     0.7519      1.926          4        640: 100%|| 105/105 [02:33<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:16<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.929      0.976      0.989      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      5.74G      1.483     0.7483      1.905          4        640: 100%|| 105/105 [02:31<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:23<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.976      0.983      0.995      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      5.76G      1.454     0.7096      1.906          4        640: 100%|| 105/105 [02:32<00:00,  1.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:17<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.929      0.989      0.995      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      5.74G       1.42     0.7108       1.88          4        640: 100%|| 105/105 [02:31<00:00,  1.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:23<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.901       0.99      0.992      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 1.253 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics 8.3.97  Python-3.10.8 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,287,022 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 15/15 [00:12<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        120      0.929      0.976      0.989      0.545\n",
      "                 hello         10         10      0.815      0.882      0.962      0.626\n",
      "              ILOVEYOU         19         19      0.932          1      0.995      0.638\n",
      "                   YES         12         12      0.992          1      0.995      0.523\n",
      "                    NO         10         10      0.944        0.9      0.972      0.453\n",
      "             THANK YOU         14         14      0.989          1      0.995      0.583\n",
      "                PLEASE         13         13      0.859          1      0.995      0.541\n",
      "                  I/ME          7          7      0.875          1      0.995       0.54\n",
      "                  WANT         12         12          1      0.979      0.995      0.552\n",
      "                    GO          9          9      0.949          1      0.995      0.514\n",
      "                 WATER         14         14      0.933          1      0.995      0.475\n",
      "Speed: 0.8ms preprocess, 20.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f6324532050>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,     0.83333,     0.83333,           0],\n",
      "       [          1,           1,           1, ...,           1,           1,           0],\n",
      "       [          1,           1,           1, ...,           1,           1,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,           1,           1,           0],\n",
      "       [          1,           1,           1, ...,           1,           1,           0],\n",
      "       [          1,           1,           1, ...,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.33333,     0.33333,     0.45137, ...,           0,           0,           0],\n",
      "       [    0.46341,     0.46341,     0.53376, ...,           0,           0,           0],\n",
      "       [    0.64865,     0.64865,     0.80152, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [    0.32432,     0.32432,     0.53795, ...,           0,           0,           0],\n",
      "       [    0.21176,     0.21176,       0.291, ...,           0,           0,           0],\n",
      "       [    0.44444,     0.44444,     0.65622, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[        0.2,         0.2,     0.29146, ...,           1,           1,           1],\n",
      "       [    0.30159,     0.30159,     0.36403, ...,           1,           1,           1],\n",
      "       [       0.48,        0.48,     0.66878, ...,           1,           1,           1],\n",
      "       ...,\n",
      "       [    0.19355,     0.19355,     0.36794, ...,           1,           1,           1],\n",
      "       [    0.11842,     0.11842,     0.17028, ...,           1,           1,           1],\n",
      "       [    0.28571,     0.28571,     0.48834, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       ...,\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
      "fitness: np.float64(0.5890088635180533)\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.62605,     0.63783,     0.52334,     0.45283,     0.58331,     0.54106,      0.5404,     0.55186,     0.51361,     0.47498])\n",
      "names: {0: 'hello', 1: 'ILOVEYOU', 2: 'YES', 3: 'NO', 4: 'THANK YOU', 5: 'PLEASE', 6: 'I/ME', 7: 'WANT', 8: 'GO', 9: 'WATER'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': np.float64(0.9287698807376372), 'metrics/recall(B)': np.float64(0.9761089300586441), 'metrics/mAP50(B)': np.float64(0.9893589743589741), 'metrics/mAP50-95(B)': np.float64(0.544525517869062), 'fitness': np.float64(0.5890088635180533)}\n",
      "save_dir: PosixPath('runs/detect/train2')\n",
      "speed: {'preprocess': 0.7827936999926047, 'inference': 20.93532559998342, 'loss': 0.012531066666573071, 'postprocess': 1.0876750750033655}\n",
      "task: 'detect'\n"
     ]
    }
   ],
   "source": [
    "# training yolov11 \n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "def check_pytorch_cuda():\n",
    "    print(\"Checking CUDA for PyTorch...\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch CUDA is available!\")\n",
    "        print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"Number of GPUs detected by PyTorch: {torch.cuda.device_count()}\")\n",
    "        print(f\"GPU Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"CUDA is NOT available in PyTorch!\")\n",
    "\n",
    "def main():\n",
    "    print(\"=== CUDA Environment Check ===\")\n",
    "    check_pytorch_cuda()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "model = YOLO(r\"/mnt/e/_clgproject/new_project/yolo11l.pt\")\n",
    "results = model.train(data=r\"/mnt/e/_clgproject/new_project/V8_final_dataset/V8_final_dataset/data.yaml\",cache=False,amp=False, workers=2, epochs=25, imgsz=640, device=0,batch=4)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (8.3.97)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (5.9.1)\n",
      "Requirement already satisfied: py-cpuinfo in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/avishkar/miniconda3/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 480x640 (no detections), 459.4ms\n",
      "0: 480x640 (no detections), 356.9ms\n",
      "0: 480x640 (no detections), 341.0ms\n",
      "0: 480x640 (no detections), 352.1ms\n",
      "0: 480x640 (no detections), 386.1ms\n",
      "0: 480x640 1 hello, 400.7ms\n",
      "0: 480x640 1 hello, 416.6ms\n",
      "0: 480x640 1 hello, 376.9ms\n",
      "0: 480x640 1 hello, 351.3ms\n",
      "0: 480x640 1 hello, 406.7ms\n",
      "0: 480x640 (no detections), 385.3ms\n",
      "0: 480x640 1 ILOVEYOU, 408.5ms\n",
      "0: 480x640 1 ILOVEYOU, 377.3ms\n",
      "0: 480x640 1 ILOVEYOU, 392.6ms\n",
      "0: 480x640 1 ILOVEYOU, 395.8ms\n",
      "0: 480x640 1 ILOVEYOU, 387.5ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 377.8ms\n",
      "0: 480x640 (no detections), 321.9ms\n",
      "0: 480x640 (no detections), 402.0ms\n",
      "0: 480x640 1 NO, 382.0ms\n",
      "0: 480x640 1 NO, 431.6ms\n",
      "0: 480x640 1 NO, 390.2ms\n",
      "0: 480x640 1 NO, 398.5ms\n",
      "0: 480x640 (no detections), 364.7ms\n",
      "0: 480x640 1 YES, 409.4ms\n",
      "0: 480x640 1 YES, 410.9ms\n",
      "0: 480x640 1 YES, 387.0ms\n",
      "0: 480x640 1 YES, 392.3ms\n",
      "0: 480x640 1 YES, 416.6ms\n",
      "0: 480x640 (no detections), 423.9ms\n",
      "0: 480x640 (no detections), 387.0ms\n",
      "0: 480x640 (no detections), 384.7ms\n",
      "0: 480x640 (no detections), 423.6ms\n",
      "0: 480x640 (no detections), 415.8ms\n",
      "0: 480x640 (no detections), 390.7ms\n",
      "0: 480x640 (no detections), 435.5ms\n",
      "0: 480x640 (no detections), 458.8ms\n",
      "0: 480x640 (no detections), 354.3ms\n",
      "0: 480x640 (no detections), 313.6ms\n",
      "0: 480x640 (no detections), 344.3ms\n",
      "0: 480x640 (no detections), 363.0ms\n",
      "0: 480x640 (no detections), 365.1ms\n",
      "0: 480x640 (no detections), 369.2ms\n",
      "0: 480x640 (no detections), 395.8ms\n",
      "0: 480x640 (no detections), 381.8ms\n",
      "0: 480x640 (no detections), 384.5ms\n",
      "0: 480x640 (no detections), 413.7ms\n",
      "0: 480x640 (no detections), 384.0ms\n",
      "0: 480x640 (no detections), 385.4ms\n",
      "0: 480x640 (no detections), 352.7ms\n",
      "0: 480x640 (no detections), 421.9ms\n",
      "0: 480x640 (no detections), 364.8ms\n",
      "0: 480x640 1 THANK YOU, 379.5ms\n",
      "0: 480x640 (no detections), 370.2ms\n",
      "0: 480x640 1 THANK YOU, 349.1ms\n",
      "0: 480x640 1 THANK YOU, 316.7ms\n",
      "0: 480x640 1 THANK YOU, 326.7ms\n",
      "0: 480x640 (no detections), 308.9ms\n",
      "0: 480x640 1 THANK YOU, 286.1ms\n",
      "0: 480x640 (no detections), 302.2ms\n",
      "0: 480x640 (no detections), 288.4ms\n",
      "0: 480x640 (no detections), 271.4ms\n",
      "0: 480x640 (no detections), 274.0ms\n",
      "0: 480x640 (no detections), 347.9ms\n",
      "0: 480x640 (no detections), 390.6ms\n",
      "0: 480x640 (no detections), 364.6ms\n",
      "0: 480x640 (no detections), 347.0ms\n",
      "0: 480x640 (no detections), 364.3ms\n",
      "0: 480x640 (no detections), 352.6ms\n",
      "0: 480x640 (no detections), 339.9ms\n",
      "0: 480x640 (no detections), 373.5ms\n",
      "0: 480x640 (no detections), 333.0ms\n",
      "0: 480x640 (no detections), 342.4ms\n",
      "0: 480x640 (no detections), 384.9ms\n",
      "0: 480x640 (no detections), 347.5ms\n",
      "0: 480x640 (no detections), 312.3ms\n",
      "0: 480x640 (no detections), 315.6ms\n",
      "0: 480x640 (no detections), 369.5ms\n",
      "0: 480x640 (no detections), 300.9ms\n",
      "0: 480x640 (no detections), 334.7ms\n",
      "0: 480x640 (no detections), 327.3ms\n",
      "0: 480x640 (no detections), 380.9ms\n",
      "0: 480x640 (no detections), 331.3ms\n",
      "0: 480x640 (no detections), 333.1ms\n",
      "0: 480x640 (no detections), 303.0ms\n",
      "0: 480x640 (no detections), 330.0ms\n",
      "0: 480x640 (no detections), 304.4ms\n",
      "0: 480x640 (no detections), 287.3ms\n",
      "0: 480x640 (no detections), 285.3ms\n",
      "0: 480x640 (no detections), 334.4ms\n",
      "0: 480x640 (no detections), 302.8ms\n",
      "0: 480x640 (no detections), 309.4ms\n",
      "0: 480x640 (no detections), 330.3ms\n",
      "0: 480x640 (no detections), 360.4ms\n",
      "0: 480x640 (no detections), 326.2ms\n",
      "0: 480x640 (no detections), 336.3ms\n",
      "0: 480x640 (no detections), 317.4ms\n",
      "0: 480x640 (no detections), 384.9ms\n",
      "0: 480x640 (no detections), 339.8ms\n",
      "0: 480x640 (no detections), 313.0ms\n",
      "0: 480x640 (no detections), 313.3ms\n",
      "0: 480x640 (no detections), 319.7ms\n",
      "0: 480x640 (no detections), 319.3ms\n",
      "0: 480x640 (no detections), 297.1ms\n",
      "0: 480x640 (no detections), 299.7ms\n",
      "0: 480x640 (no detections), 297.7ms\n",
      "0: 480x640 (no detections), 336.5ms\n",
      "0: 480x640 (no detections), 345.2ms\n",
      "0: 480x640 (no detections), 354.9ms\n",
      "0: 480x640 1 hello, 317.2ms\n",
      "0: 480x640 1 hello, 324.5ms\n",
      "0: 480x640 1 hello, 320.1ms\n",
      "0: 480x640 1 hello, 311.8ms\n",
      "0: 480x640 1 ILOVEYOU, 341.7ms\n",
      "0: 480x640 1 ILOVEYOU, 353.0ms\n",
      "0: 480x640 1 ILOVEYOU, 341.6ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 345.1ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 331.8ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 322.3ms\n",
      "0: 480x640 (no detections), 298.8ms\n",
      "0: 480x640 (no detections), 300.1ms\n",
      "0: 480x640 1 ILOVEYOU, 378.4ms\n",
      "0: 480x640 1 ILOVEYOU, 368.5ms\n",
      "0: 480x640 1 ILOVEYOU, 349.1ms\n",
      "0: 480x640 (no detections), 338.9ms\n",
      "0: 480x640 (no detections), 335.6ms\n",
      "0: 480x640 (no detections), 358.2ms\n",
      "0: 480x640 (no detections), 314.5ms\n",
      "0: 480x640 (no detections), 331.6ms\n",
      "0: 480x640 (no detections), 359.9ms\n",
      "0: 480x640 1 hello, 349.0ms\n",
      "0: 480x640 (no detections), 343.9ms\n",
      "0: 480x640 (no detections), 311.9ms\n",
      "0: 480x640 1 hello, 309.1ms\n",
      "0: 480x640 (no detections), 310.5ms\n",
      "0: 480x640 1 PLEASE, 310.8ms\n",
      "0: 480x640 1 PLEASE, 342.9ms\n",
      "0: 480x640 1 PLEASE, 316.4ms\n",
      "0: 480x640 1 PLEASE, 304.4ms\n",
      "0: 480x640 (no detections), 283.3ms\n",
      "0: 480x640 (no detections), 316.8ms\n",
      "0: 480x640 1 PLEASE, 350.9ms\n",
      "0: 480x640 1 PLEASE, 359.8ms\n",
      "0: 480x640 1 PLEASE, 363.3ms\n",
      "0: 480x640 1 PLEASE, 372.2ms\n",
      "0: 480x640 1 PLEASE, 362.0ms\n",
      "0: 480x640 1 PLEASE, 342.6ms\n",
      "0: 480x640 (no detections), 318.6ms\n",
      "0: 480x640 (no detections), 326.8ms\n",
      "0: 480x640 1 PLEASE, 405.2ms\n",
      "0: 480x640 1 PLEASE, 384.3ms\n",
      "0: 480x640 (no detections), 384.5ms\n",
      "0: 480x640 1 WATER, 385.3ms\n",
      "0: 480x640 1 WATER, 385.2ms\n",
      "0: 480x640 1 WATER, 368.2ms\n",
      "0: 480x640 1 WATER, 390.7ms\n",
      "0: 480x640 1 WATER, 394.4ms\n",
      "0: 480x640 1 WATER, 395.6ms\n",
      "0: 480x640 (no detections), 383.6ms\n",
      "0: 480x640 (no detections), 388.2ms\n",
      "0: 480x640 (no detections), 395.6ms\n",
      "0: 480x640 (no detections), 399.0ms\n",
      "0: 480x640 (no detections), 379.1ms\n",
      "0: 480x640 (no detections), 383.7ms\n",
      "0: 480x640 (no detections), 404.8ms\n",
      "0: 480x640 (no detections), 405.2ms\n",
      "0: 480x640 (no detections), 385.3ms\n",
      "0: 480x640 (no detections), 353.2ms\n",
      "0: 480x640 (no detections), 378.9ms\n",
      "0: 480x640 (no detections), 360.8ms\n",
      "0: 480x640 (no detections), 387.5ms\n",
      "0: 480x640 (no detections), 397.8ms\n",
      "0: 480x640 (no detections), 359.7ms\n",
      "0: 480x640 (no detections), 316.5ms\n",
      "0: 480x640 (no detections), 305.6ms\n",
      "0: 480x640 (no detections), 299.9ms\n",
      "0: 480x640 (no detections), 380.5ms\n",
      "0: 480x640 1 WANT, 415.9ms\n",
      "0: 480x640 (no detections), 375.8ms\n",
      "0: 480x640 1 WANT, 396.2ms\n",
      "0: 480x640 (no detections), 369.5ms\n",
      "0: 480x640 (no detections), 392.3ms\n",
      "0: 480x640 (no detections), 385.7ms\n",
      "0: 480x640 1 I/ME, 393.9ms\n",
      "0: 480x640 1 I/ME, 402.9ms\n",
      "0: 480x640 (no detections), 414.5ms\n",
      "0: 480x640 (no detections), 403.0ms\n",
      "0: 480x640 1 I/ME, 415.8ms\n",
      "0: 480x640 1 I/ME, 346.8ms\n",
      "0: 480x640 1 I/ME, 342.8ms\n",
      "0: 480x640 1 I/ME, 363.1ms\n",
      "0: 480x640 1 I/ME, 385.0ms\n",
      "0: 480x640 1 I/ME, 376.1ms\n",
      "0: 480x640 (no detections), 367.2ms\n",
      "0: 480x640 (no detections), 384.6ms\n",
      "0: 480x640 (no detections), 354.1ms\n",
      "0: 480x640 (no detections), 395.6ms\n",
      "0: 480x640 (no detections), 354.9ms\n",
      "0: 480x640 (no detections), 357.4ms\n",
      "0: 480x640 (no detections), 373.2ms\n",
      "0: 480x640 (no detections), 350.8ms\n",
      "0: 480x640 (no detections), 381.4ms\n",
      "0: 480x640 (no detections), 361.1ms\n",
      "0: 480x640 (no detections), 419.7ms\n",
      "0: 480x640 (no detections), 381.1ms\n",
      "0: 480x640 (no detections), 368.5ms\n",
      "0: 480x640 (no detections), 386.7ms\n",
      "0: 480x640 (no detections), 381.4ms\n",
      "0: 480x640 1 hello, 395.0ms\n",
      "0: 480x640 1 hello, 369.7ms\n",
      "0: 480x640 1 hello, 384.9ms\n",
      "0: 480x640 1 hello, 375.5ms\n",
      "0: 480x640 1 hello, 432.5ms\n",
      "0: 480x640 1 ILOVEYOU, 410.3ms\n",
      "0: 480x640 1 ILOVEYOU, 408.8ms\n",
      "0: 480x640 1 ILOVEYOU, 349.9ms\n",
      "0: 480x640 1 ILOVEYOU, 372.8ms\n",
      "0: 480x640 1 ILOVEYOU, 364.0ms\n",
      "0: 480x640 (no detections), 355.6ms\n",
      "0: 480x640 (no detections), 376.2ms\n",
      "0: 480x640 (no detections), 354.0ms\n",
      "0: 480x640 (no detections), 386.3ms\n",
      "0: 480x640 1 GO, 380.5ms\n",
      "0: 480x640 (no detections), 336.3ms\n",
      "0: 480x640 (no detections), 371.2ms\n",
      "0: 480x640 (no detections), 450.3ms\n",
      "0: 480x640 (no detections), 401.1ms\n",
      "0: 480x640 (no detections), 383.2ms\n",
      "0: 480x640 (no detections), 403.2ms\n",
      "0: 480x640 (no detections), 386.3ms\n",
      "0: 480x640 (no detections), 384.5ms\n",
      "0: 480x640 (no detections), 359.1ms\n",
      "0: 480x640 1 GO, 440.7ms\n",
      "0: 480x640 1 GO, 387.5ms\n",
      "0: 480x640 (no detections), 342.3ms\n",
      "0: 480x640 1 GO, 344.8ms\n",
      "0: 480x640 (no detections), 397.6ms\n",
      "0: 480x640 1 GO, 391.7ms\n",
      "0: 480x640 (no detections), 421.9ms\n",
      "0: 480x640 (no detections), 371.2ms\n",
      "0: 480x640 (no detections), 358.9ms\n",
      "0: 480x640 (no detections), 347.7ms\n",
      "0: 480x640 (no detections), 417.0ms\n",
      "0: 480x640 (no detections), 386.1ms\n",
      "0: 480x640 (no detections), 414.8ms\n",
      "0: 480x640 (no detections), 378.6ms\n",
      "0: 480x640 (no detections), 379.2ms\n",
      "0: 480x640 (no detections), 357.5ms\n",
      "0: 480x640 (no detections), 334.0ms\n",
      "0: 480x640 (no detections), 325.9ms\n",
      "0: 480x640 (no detections), 364.5ms\n",
      "0: 480x640 1 hello, 1 GO, 316.5ms\n",
      "0: 480x640 1 hello, 1 GO, 366.4ms\n",
      "0: 480x640 1 hello, 1 GO, 345.8ms\n",
      "0: 480x640 1 hello, 1 GO, 348.8ms\n",
      "0: 480x640 1 hello, 356.7ms\n",
      "0: 480x640 1 hello, 360.6ms\n",
      "0: 480x640 1 hello, 333.9ms\n",
      "0: 480x640 1 hello, 342.1ms\n",
      "0: 480x640 1 hello, 339.7ms\n",
      "0: 480x640 1 hello, 321.4ms\n",
      "0: 480x640 1 hello, 328.9ms\n",
      "0: 480x640 1 hello, 343.3ms\n",
      "0: 480x640 1 hello, 333.5ms\n",
      "0: 480x640 1 hello, 290.8ms\n",
      "0: 480x640 1 hello, 288.9ms\n",
      "0: 480x640 1 hello, 329.3ms\n",
      "0: 480x640 1 hello, 355.2ms\n",
      "0: 480x640 1 hello, 374.2ms\n",
      "0: 480x640 1 ILOVEYOU, 360.2ms\n",
      "0: 480x640 1 ILOVEYOU, 345.2ms\n",
      "0: 480x640 1 ILOVEYOU, 386.9ms\n",
      "0: 480x640 (no detections), 352.5ms\n",
      "0: 480x640 (no detections), 345.8ms\n",
      "0: 480x640 (no detections), 352.9ms\n",
      "0: 480x640 (no detections), 392.6ms\n",
      "0: 480x640 (no detections), 355.1ms\n",
      "0: 480x640 1 YES, 335.8ms\n",
      "0: 480x640 1 YES, 345.4ms\n",
      "0: 480x640 1 YES, 336.8ms\n",
      "0: 480x640 1 YES, 341.9ms\n",
      "0: 480x640 (no detections), 337.9ms\n",
      "0: 480x640 1 NO, 312.4ms\n",
      "0: 480x640 1 NO, 377.9ms\n",
      "0: 480x640 1 NO, 371.7ms\n",
      "0: 480x640 1 NO, 382.8ms\n",
      "0: 480x640 (no detections), 386.2ms\n",
      "0: 480x640 (no detections), 394.9ms\n",
      "0: 480x640 1 I/ME, 360.9ms\n",
      "0: 480x640 (no detections), 383.1ms\n",
      "0: 480x640 (no detections), 378.2ms\n",
      "0: 480x640 1 I/ME, 394.3ms\n",
      "0: 480x640 (no detections), 370.1ms\n",
      "0: 480x640 (no detections), 408.8ms\n",
      "0: 480x640 (no detections), 425.3ms\n",
      "0: 480x640 (no detections), 357.4ms\n",
      "0: 480x640 (no detections), 415.1ms\n",
      "0: 480x640 (no detections), 372.9ms\n",
      "0: 480x640 (no detections), 387.9ms\n",
      "0: 480x640 (no detections), 357.4ms\n",
      "0: 480x640 (no detections), 367.0ms\n",
      "0: 480x640 (no detections), 358.6ms\n",
      "0: 480x640 (no detections), 403.5ms\n",
      "0: 480x640 (no detections), 402.8ms\n",
      "0: 480x640 (no detections), 389.3ms\n",
      "0: 480x640 (no detections), 397.7ms\n",
      "0: 480x640 (no detections), 370.6ms\n",
      "0: 480x640 (no detections), 379.7ms\n",
      "0: 480x640 (no detections), 381.3ms\n",
      "0: 480x640 (no detections), 353.5ms\n",
      "0: 480x640 (no detections), 380.7ms\n",
      "0: 480x640 (no detections), 396.2ms\n",
      "0: 480x640 (no detections), 413.2ms\n",
      "0: 480x640 (no detections), 382.2ms\n",
      "0: 480x640 (no detections), 379.9ms\n",
      "0: 480x640 (no detections), 383.0ms\n",
      "0: 480x640 (no detections), 418.4ms\n",
      "0: 480x640 (no detections), 365.7ms\n",
      "0: 480x640 1 THANK YOU, 390.6ms\n",
      "0: 480x640 (no detections), 383.3ms\n",
      "0: 480x640 (no detections), 381.5ms\n",
      "0: 480x640 (no detections), 387.8ms\n",
      "0: 480x640 (no detections), 375.8ms\n",
      "0: 480x640 (no detections), 385.7ms\n",
      "0: 480x640 (no detections), 399.8ms\n",
      "0: 480x640 (no detections), 365.4ms\n",
      "0: 480x640 (no detections), 413.8ms\n",
      "0: 480x640 (no detections), 378.4ms\n",
      "0: 480x640 (no detections), 405.7ms\n",
      "0: 480x640 (no detections), 384.2ms\n",
      "0: 480x640 (no detections), 364.1ms\n",
      "0: 480x640 (no detections), 421.4ms\n",
      "0: 480x640 (no detections), 386.7ms\n",
      "0: 480x640 (no detections), 426.4ms\n",
      "0: 480x640 (no detections), 355.2ms\n",
      "0: 480x640 (no detections), 413.1ms\n",
      "0: 480x640 (no detections), 389.1ms\n",
      "0: 480x640 (no detections), 389.6ms\n",
      "0: 480x640 (no detections), 424.8ms\n",
      "0: 480x640 (no detections), 404.5ms\n",
      "0: 480x640 (no detections), 392.4ms\n",
      "0: 480x640 (no detections), 349.5ms\n",
      "0: 480x640 1 WATER, 295.7ms\n",
      "0: 480x640 1 WATER, 361.4ms\n",
      "0: 480x640 1 WATER, 399.0ms\n",
      "0: 480x640 1 WATER, 394.8ms\n",
      "0: 480x640 (no detections), 389.3ms\n",
      "0: 480x640 1 PLEASE, 408.3ms\n",
      "0: 480x640 1 PLEASE, 395.2ms\n",
      "0: 480x640 (no detections), 372.7ms\n",
      "0: 480x640 (no detections), 397.9ms\n",
      "0: 480x640 (no detections), 402.8ms\n",
      "0: 480x640 (no detections), 428.2ms\n",
      "0: 480x640 1 PLEASE, 386.7ms\n",
      "0: 480x640 1 PLEASE, 419.8ms\n",
      "0: 480x640 1 PLEASE, 416.4ms\n",
      "0: 480x640 (no detections), 393.2ms\n",
      "0: 480x640 (no detections), 392.6ms\n",
      "0: 480x640 (no detections), 396.8ms\n",
      "0: 480x640 (no detections), 360.0ms\n",
      "0: 480x640 (no detections), 376.1ms\n",
      "0: 480x640 1 PLEASE, 396.0ms\n",
      "0: 480x640 (no detections), 370.4ms\n",
      "0: 480x640 1 PLEASE, 384.6ms\n",
      "0: 480x640 (no detections), 341.4ms\n",
      "0: 480x640 (no detections), 375.3ms\n",
      "0: 480x640 (no detections), 379.5ms\n",
      "0: 480x640 (no detections), 390.6ms\n",
      "0: 480x640 (no detections), 408.2ms\n",
      "0: 480x640 (no detections), 370.6ms\n",
      "0: 480x640 (no detections), 383.8ms\n",
      "0: 480x640 (no detections), 355.2ms\n",
      "0: 480x640 (no detections), 370.5ms\n",
      "0: 480x640 (no detections), 394.8ms\n",
      "0: 480x640 (no detections), 393.1ms\n",
      "0: 480x640 (no detections), 390.6ms\n",
      "0: 480x640 (no detections), 399.7ms\n",
      "0: 480x640 (no detections), 376.3ms\n",
      "0: 480x640 (no detections), 396.5ms\n",
      "0: 480x640 (no detections), 383.3ms\n",
      "0: 480x640 (no detections), 356.6ms\n",
      "0: 480x640 (no detections), 392.2ms\n",
      "0: 480x640 (no detections), 368.5ms\n",
      "0: 480x640 (no detections), 383.7ms\n",
      "0: 480x640 (no detections), 385.3ms\n",
      "0: 480x640 (no detections), 366.1ms\n",
      "0: 480x640 (no detections), 380.9ms\n",
      "0: 480x640 (no detections), 373.2ms\n",
      "0: 480x640 (no detections), 401.2ms\n",
      "0: 480x640 (no detections), 382.0ms\n",
      "0: 480x640 (no detections), 391.1ms\n",
      "0: 480x640 (no detections), 370.2ms\n",
      "0: 480x640 (no detections), 410.4ms\n",
      "0: 480x640 (no detections), 387.5ms\n",
      "0: 480x640 (no detections), 394.3ms\n",
      "0: 480x640 (no detections), 367.9ms\n",
      "0: 480x640 (no detections), 351.2ms\n",
      "0: 480x640 (no detections), 367.2ms\n",
      "0: 480x640 (no detections), 376.4ms\n",
      "0: 480x640 (no detections), 329.5ms\n",
      "0: 480x640 (no detections), 302.4ms\n",
      "0: 480x640 (no detections), 275.8ms\n",
      "0: 480x640 (no detections), 288.7ms\n",
      "0: 480x640 (no detections), 297.3ms\n",
      "0: 480x640 (no detections), 338.7ms\n",
      "0: 480x640 (no detections), 358.2ms\n",
      "0: 480x640 (no detections), 354.3ms\n",
      "0: 480x640 (no detections), 434.5ms\n",
      "0: 480x640 (no detections), 396.5ms\n",
      "0: 480x640 (no detections), 401.4ms\n",
      "0: 480x640 (no detections), 375.9ms\n",
      "0: 480x640 (no detections), 389.0ms\n",
      "0: 480x640 (no detections), 377.8ms\n",
      "0: 480x640 (no detections), 381.5ms\n",
      "0: 480x640 (no detections), 357.1ms\n",
      "0: 480x640 (no detections), 372.4ms\n",
      "0: 480x640 (no detections), 355.8ms\n",
      "0: 480x640 (no detections), 322.9ms\n",
      "0: 480x640 1 hello, 332.1ms\n",
      "0: 480x640 1 hello, 350.6ms\n",
      "0: 480x640 (no detections), 346.4ms\n",
      "0: 480x640 1 hello, 344.3ms\n",
      "0: 480x640 (no detections), 395.7ms\n",
      "0: 480x640 (no detections), 372.7ms\n",
      "0: 480x640 (no detections), 374.4ms\n",
      "0: 480x640 (no detections), 397.5ms\n",
      "0: 480x640 (no detections), 367.4ms\n",
      "0: 480x640 (no detections), 354.6ms\n",
      "0: 480x640 (no detections), 360.0ms\n",
      "0: 480x640 (no detections), 340.7ms\n",
      "0: 480x640 (no detections), 322.9ms\n",
      "0: 480x640 (no detections), 325.5ms\n",
      "0: 480x640 (no detections), 366.2ms\n",
      "0: 480x640 (no detections), 322.3ms\n",
      "0: 480x640 (no detections), 385.4ms\n",
      "0: 480x640 (no detections), 389.8ms\n",
      "0: 480x640 (no detections), 335.8ms\n",
      "0: 480x640 (no detections), 368.5ms\n",
      "0: 480x640 (no detections), 318.8ms\n",
      "0: 480x640 (no detections), 333.5ms\n",
      "0: 480x640 (no detections), 350.9ms\n",
      "0: 480x640 (no detections), 304.9ms\n",
      "0: 480x640 (no detections), 339.2ms\n",
      "0: 480x640 (no detections), 400.5ms\n",
      "0: 480x640 (no detections), 349.5ms\n",
      "0: 480x640 (no detections), 336.8ms\n",
      "0: 480x640 (no detections), 322.2ms\n",
      "0: 480x640 (no detections), 340.2ms\n",
      "0: 480x640 (no detections), 344.6ms\n",
      "0: 480x640 (no detections), 317.1ms\n",
      "0: 480x640 (no detections), 342.1ms\n",
      "0: 480x640 (no detections), 340.3ms\n",
      "0: 480x640 (no detections), 316.2ms\n",
      "0: 480x640 (no detections), 317.3ms\n",
      "0: 480x640 (no detections), 330.5ms\n",
      "0: 480x640 (no detections), 322.2ms\n",
      "0: 480x640 (no detections), 305.4ms\n",
      "0: 480x640 (no detections), 324.2ms\n",
      "0: 480x640 (no detections), 379.3ms\n",
      "0: 480x640 (no detections), 313.1ms\n",
      "0: 480x640 (no detections), 311.9ms\n",
      "0: 480x640 (no detections), 289.4ms\n",
      "0: 480x640 (no detections), 289.0ms\n",
      "0: 480x640 (no detections), 323.7ms\n",
      "0: 480x640 (no detections), 320.9ms\n",
      "0: 480x640 (no detections), 352.8ms\n",
      "0: 480x640 (no detections), 330.7ms\n",
      "0: 480x640 (no detections), 340.6ms\n",
      "0: 480x640 (no detections), 334.2ms\n",
      "0: 480x640 (no detections), 340.0ms\n",
      "0: 480x640 (no detections), 347.1ms\n",
      "0: 480x640 (no detections), 320.2ms\n",
      "0: 480x640 (no detections), 341.2ms\n",
      "0: 480x640 (no detections), 328.4ms\n",
      "0: 480x640 (no detections), 328.3ms\n",
      "0: 480x640 (no detections), 317.9ms\n",
      "0: 480x640 (no detections), 332.8ms\n",
      "0: 480x640 (no detections), 345.7ms\n",
      "0: 480x640 (no detections), 386.0ms\n",
      "0: 480x640 (no detections), 361.4ms\n",
      "0: 480x640 (no detections), 393.3ms\n",
      "0: 480x640 (no detections), 380.6ms\n",
      "0: 480x640 (no detections), 371.0ms\n",
      "0: 480x640 (no detections), 356.5ms\n",
      "0: 480x640 (no detections), 365.8ms\n",
      "0: 480x640 (no detections), 359.3ms\n",
      "0: 480x640 (no detections), 346.0ms\n",
      "0: 480x640 (no detections), 336.6ms\n",
      "0: 480x640 1 hello, 356.7ms\n",
      "0: 480x640 (no detections), 354.0ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 346.0ms\n",
      "0: 480x640 1 hello, 346.7ms\n",
      "0: 480x640 1 hello, 351.2ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 367.9ms\n",
      "0: 480x640 1 hello, 1 ILOVEYOU, 328.6ms\n",
      "0: 480x640 (no detections), 308.5ms\n",
      "0: 480x640 (no detections), 280.6ms\n",
      "0: 480x640 (no detections), 363.5ms\n",
      "0: 480x640 (no detections), 330.4ms\n",
      "0: 480x640 (no detections), 364.1ms\n",
      "0: 480x640 1 GO, 388.3ms\n",
      "0: 480x640 1 PLEASE, 1 GO, 351.2ms\n",
      "0: 480x640 (no detections), 384.8ms\n",
      "0: 480x640 (no detections), 376.6ms\n",
      "0: 480x640 (no detections), 379.4ms\n",
      "0: 480x640 (no detections), 351.5ms\n",
      "0: 480x640 1 PLEASE, 1 I/ME, 349.5ms\n",
      "0: 480x640 (no detections), 351.1ms\n",
      "0: 480x640 (no detections), 358.3ms\n",
      "0: 480x640 (no detections), 408.0ms\n",
      "0: 480x640 (no detections), 398.3ms\n",
      "0: 480x640 (no detections), 408.6ms\n",
      "0: 480x640 (no detections), 410.2ms\n",
      "0: 480x640 (no detections), 381.5ms\n",
      "0: 480x640 1 WATER, 317.0ms\n",
      "0: 480x640 1 WATER, 323.0ms\n",
      "0: 480x640 1 WATER, 343.6ms\n",
      "0: 480x640 (no detections), 403.3ms\n",
      "0: 480x640 (no detections), 341.6ms\n",
      "0: 480x640 (no detections), 335.8ms\n",
      "0: 480x640 (no detections), 334.4ms\n",
      "0: 480x640 (no detections), 323.4ms\n",
      "0: 480x640 (no detections), 346.2ms\n",
      "0: 480x640 (no detections), 325.9ms\n",
      "0: 480x640 (no detections), 336.7ms\n",
      "0: 480x640 (no detections), 322.1ms\n",
      "0: 480x640 (no detections), 315.9ms\n",
      "0: 480x640 (no detections), 370.0ms\n",
      "0: 480x640 (no detections), 323.9ms\n",
      "0: 480x640 1 I/ME, 319.9ms\n",
      "0: 480x640 (no detections), 337.6ms\n",
      "0: 480x640 (no detections), 331.3ms\n",
      "0: 480x640 1 GO, 323.2ms\n",
      "0: 480x640 (no detections), 287.6ms\n",
      "0: 480x640 (no detections), 302.0ms\n",
      "0: 480x640 (no detections), 366.0ms\n",
      "0: 480x640 (no detections), 347.5ms\n",
      "0: 480x640 (no detections), 399.6ms\n",
      "0: 480x640 (no detections), 369.4ms\n",
      "0: 480x640 (no detections), 376.6ms\n",
      "0: 480x640 (no detections), 386.9ms\n",
      "0: 480x640 (no detections), 364.1ms\n",
      "0: 480x640 1 WANT, 368.9ms\n",
      "0: 480x640 1 WANT, 371.0ms\n",
      "0: 480x640 (no detections), 357.4ms\n",
      "0: 480x640 1 WANT, 363.3ms\n",
      "0: 480x640 (no detections), 362.7ms\n",
      "0: 480x640 (no detections), 405.2ms\n",
      "0: 480x640 (no detections), 368.4ms\n",
      "0: 480x640 1 WATER, 342.0ms\n",
      "0: 480x640 2 WATERs, 400.1ms\n",
      "0: 480x640 2 WATERs, 390.3ms\n",
      "0: 480x640 2 WATERs, 390.7ms\n",
      "0: 480x640 1 WATER, 315.5ms\n",
      "0: 480x640 1 WATER, 365.2ms\n",
      "0: 480x640 (no detections), 370.7ms\n",
      "0: 480x640 1 PLEASE, 1 GO, 335.3ms\n",
      "0: 480x640 (no detections), 330.4ms\n",
      "0: 480x640 (no detections), 348.6ms\n",
      "0: 480x640 1 PLEASE, 358.6ms\n",
      "0: 480x640 (no detections), 326.6ms\n",
      "0: 480x640 (no detections), 367.9ms\n",
      "0: 480x640 (no detections), 322.9ms\n",
      "0: 480x640 (no detections), 351.1ms\n",
      "0: 480x640 (no detections), 361.5ms\n",
      "0: 480x640 (no detections), 384.4ms\n",
      "0: 480x640 (no detections), 361.8ms\n",
      "0: 480x640 (no detections), 407.3ms\n",
      "0: 480x640 (no detections), 408.3ms\n",
      "0: 480x640 (no detections), 318.2ms\n",
      "0: 480x640 1 GO, 356.0ms\n",
      "0: 480x640 (no detections), 312.8ms\n",
      "0: 480x640 1 GO, 302.9ms\n",
      "0: 480x640 (no detections), 367.9ms\n",
      "0: 480x640 (no detections), 402.9ms\n",
      "0: 480x640 (no detections), 412.6ms\n",
      "0: 480x640 1 GO, 389.4ms\n",
      "0: 480x640 (no detections), 363.7ms\n",
      "0: 480x640 (no detections), 365.5ms\n",
      "0: 480x640 1 GO, 372.1ms\n",
      "0: 480x640 1 GO, 384.9ms\n",
      "0: 480x640 (no detections), 342.1ms\n",
      "0: 480x640 (no detections), 400.1ms\n",
      "0: 480x640 (no detections), 387.1ms\n",
      "0: 480x640 (no detections), 373.4ms\n",
      "0: 480x640 (no detections), 382.4ms\n",
      "0: 480x640 (no detections), 383.7ms\n",
      "0: 480x640 (no detections), 381.1ms\n",
      "0: 480x640 (no detections), 389.3ms\n",
      "0: 480x640 (no detections), 380.7ms\n",
      "0: 480x640 (no detections), 357.2ms\n",
      "0: 480x640 (no detections), 354.6ms\n",
      "0: 480x640 1 I/ME, 379.0ms\n",
      "0: 480x640 (no detections), 333.7ms\n",
      "0: 480x640 1 I/ME, 349.0ms\n",
      "0: 480x640 1 I/ME, 353.2ms\n",
      "0: 480x640 (no detections), 352.6ms\n",
      "0: 480x640 (no detections), 403.8ms\n",
      "0: 480x640 (no detections), 378.4ms\n",
      "0: 480x640 (no detections), 354.6ms\n",
      "0: 480x640 (no detections), 409.5ms\n",
      "0: 480x640 (no detections), 387.9ms\n",
      "0: 480x640 (no detections), 365.2ms\n",
      "0: 480x640 (no detections), 408.5ms\n",
      "0: 480x640 (no detections), 374.7ms\n",
      "0: 480x640 (no detections), 410.1ms\n",
      "0: 480x640 (no detections), 387.9ms\n",
      "0: 480x640 (no detections), 381.8ms\n",
      "0: 480x640 (no detections), 386.1ms\n",
      "0: 480x640 (no detections), 403.3ms\n",
      "0: 480x640 (no detections), 380.7ms\n",
      "0: 480x640 (no detections), 368.8ms\n",
      "0: 480x640 (no detections), 385.0ms\n",
      "0: 480x640 (no detections), 391.3ms\n",
      "0: 480x640 (no detections), 376.7ms\n",
      "0: 480x640 (no detections), 394.2ms\n",
      "0: 480x640 (no detections), 381.6ms\n",
      "0: 480x640 (no detections), 384.4ms\n",
      "0: 480x640 (no detections), 371.5ms\n",
      "0: 480x640 1 ILOVEYOU, 1 GO, 384.2ms\n",
      "0: 480x640 1 GO, 360.8ms\n",
      "0: 480x640 1 ILOVEYOU, 1 GO, 431.6ms\n",
      "0: 480x640 1 GO, 391.3ms\n",
      "0: 480x640 1 ILOVEYOU, 1 GO, 395.0ms\n",
      "0: 480x640 1 ILOVEYOU, 1 GO, 402.8ms\n",
      "0: 480x640 (no detections), 388.8ms\n",
      "0: 480x640 (no detections), 424.2ms\n",
      "0: 480x640 (no detections), 397.3ms\n",
      "0: 480x640 (no detections), 375.2ms\n",
      "0: 480x640 (no detections), 407.5ms\n",
      "0: 480x640 (no detections), 399.5ms\n",
      "0: 480x640 (no detections), 402.0ms\n",
      "0: 480x640 (no detections), 361.1ms\n",
      "0: 480x640 (no detections), 389.0ms\n",
      "0: 480x640 (no detections), 391.3ms\n",
      "0: 480x640 (no detections), 409.5ms\n",
      "0: 480x640 (no detections), 400.9ms\n",
      "0: 480x640 (no detections), 399.4ms\n",
      "0: 480x640 (no detections), 372.3ms\n",
      "0: 480x640 (no detections), 393.1ms\n",
      "0: 480x640 (no detections), 412.3ms\n",
      "0: 480x640 (no detections), 315.5ms\n",
      "0: 480x640 (no detections), 290.1ms\n",
      "0: 480x640 (no detections), 341.3ms\n",
      "0: 480x640 (no detections), 397.7ms\n",
      "0: 480x640 (no detections), 408.6ms\n",
      "0: 480x640 (no detections), 406.2ms\n",
      "0: 480x640 (no detections), 362.7ms\n",
      "0: 480x640 (no detections), 415.4ms\n",
      "0: 480x640 (no detections), 397.3ms\n",
      "0: 480x640 (no detections), 409.2ms\n",
      "0: 480x640 (no detections), 376.2ms\n",
      "0: 480x640 (no detections), 411.9ms\n",
      "0: 480x640 (no detections), 410.8ms\n",
      "0: 480x640 (no detections), 388.2ms\n",
      "0: 480x640 (no detections), 436.8ms\n",
      "0: 480x640 (no detections), 413.7ms\n",
      "0: 480x640 (no detections), 388.9ms\n",
      "0: 480x640 (no detections), 337.0ms\n",
      "0: 480x640 (no detections), 361.3ms\n",
      "0: 480x640 (no detections), 379.7ms\n",
      "0: 480x640 (no detections), 333.2ms\n",
      "0: 480x640 (no detections), 350.1ms\n",
      "0: 480x640 (no detections), 335.0ms\n",
      "0: 480x640 (no detections), 350.4ms\n",
      "0: 480x640 (no detections), 344.3ms\n",
      "0: 480x640 (no detections), 333.1ms\n",
      "0: 480x640 (no detections), 397.0ms\n",
      "0: 480x640 (no detections), 398.0ms\n",
      "0: 480x640 (no detections), 380.4ms\n",
      "0: 480x640 1 hello, 372.6ms\n",
      "0: 480x640 (no detections), 349.3ms\n",
      "0: 480x640 1 hello, 382.9ms\n",
      "0: 480x640 1 hello, 406.2ms\n",
      "0: 480x640 1 hello, 385.3ms\n",
      "0: 480x640 (no detections), 380.8ms\n",
      "0: 480x640 (no detections), 351.6ms\n",
      "0: 480x640 (no detections), 372.0ms\n",
      "0: 480x640 (no detections), 425.4ms\n",
      "0: 480x640 (no detections), 385.0ms\n",
      "0: 480x640 (no detections), 379.9ms\n",
      "0: 480x640 (no detections), 371.9ms\n",
      "0: 480x640 (no detections), 370.8ms\n",
      "0: 480x640 (no detections), 403.4ms\n",
      "0: 480x640 (no detections), 436.5ms\n",
      "0: 480x640 (no detections), 372.8ms\n",
      "0: 480x640 (no detections), 393.7ms\n",
      "0: 480x640 (no detections), 389.7ms\n",
      "0: 480x640 (no detections), 381.8ms\n",
      "0: 480x640 (no detections), 389.1ms\n",
      "0: 480x640 (no detections), 356.2ms\n",
      "0: 480x640 1 ILOVEYOU, 384.7ms\n",
      "0: 480x640 1 ILOVEYOU, 403.8ms\n",
      "0: 480x640 (no detections), 362.8ms\n",
      "0: 480x640 (no detections), 354.6ms\n",
      "0: 480x640 (no detections), 391.9ms\n",
      "0: 480x640 (no detections), 330.3ms\n",
      "0: 480x640 (no detections), 446.6ms\n",
      "0: 480x640 (no detections), 382.3ms\n",
      "0: 480x640 (no detections), 364.0ms\n",
      "0: 480x640 (no detections), 398.4ms\n",
      "0: 480x640 (no detections), 422.3ms\n",
      "0: 480x640 1 ILOVEYOU, 409.0ms\n",
      "0: 480x640 1 ILOVEYOU, 409.1ms\n",
      "0: 480x640 1 ILOVEYOU, 355.0ms\n",
      "0: 480x640 1 ILOVEYOU, 362.3ms\n",
      "0: 480x640 (no detections), 394.4ms\n",
      "0: 480x640 (no detections), 378.6ms\n",
      "0: 480x640 (no detections), 347.1ms\n",
      "0: 480x640 (no detections), 411.4ms\n",
      "0: 480x640 (no detections), 368.7ms\n",
      "0: 480x640 1 YES, 347.7ms\n",
      "0: 480x640 (no detections), 366.9ms\n",
      "0: 480x640 1 YES, 369.9ms\n",
      "0: 480x640 (no detections), 397.3ms\n",
      "0: 480x640 1 hello, 358.4ms\n",
      "0: 480x640 (no detections), 415.6ms\n",
      "0: 480x640 (no detections), 366.6ms\n",
      "0: 480x640 (no detections), 377.7ms\n",
      "0: 480x640 (no detections), 366.4ms\n",
      "0: 480x640 (no detections), 405.8ms\n",
      "0: 480x640 (no detections), 370.6ms\n",
      "0: 480x640 1 NO, 387.6ms\n",
      "0: 480x640 1 NO, 410.4ms\n",
      "0: 480x640 1 NO, 399.2ms\n",
      "0: 480x640 (no detections), 397.3ms\n",
      "0: 480x640 1 GO, 364.1ms\n",
      "0: 480x640 (no detections), 389.3ms\n",
      "0: 480x640 (no detections), 401.5ms\n",
      "0: 480x640 1 GO, 397.1ms\n",
      "0: 480x640 (no detections), 373.5ms\n",
      "0: 480x640 (no detections), 413.4ms\n",
      "0: 480x640 (no detections), 423.3ms\n",
      "0: 480x640 (no detections), 422.7ms\n",
      "0: 480x640 (no detections), 455.3ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_clgproject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnew_project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Run real-time detection using webcam\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\engine\\model.py:550\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\engine\\predictor.py:214\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\utils\\_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\engine\\predictor.py:323\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 323\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\engine\\predictor.py:171\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    167\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    170\u001b[0m )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:570\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 570\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\modules\\head.py:70\u001b[0m, in \u001b[0;36mDetect.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_end2end(x)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[1;32m---> 70\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:91\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\avish\\anaconda3\\envs\\pytorch_ava\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO(r\"E:\\_clgproject\\new_project\\runs\\detect\\train2\\weights\\best.pt\")\n",
    "\n",
    "# Run real-time detection using webcam\n",
    "model.predict(source=0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = YOLO(r\"E:\\_clgproject\\new_project\\runs\\detect\\train2\\weights\\best.pt\")\n",
    "\n",
    "# Custom webcam loop for more control\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Process every other frame if needed (skip n frames)\n",
    "    results = model(frame, verbose=False)  # verbose=False reduces console output\n",
    "    \n",
    "    # Display results\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('YOLOv8 Detection', annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Word: hello\n",
      "Detected Word: hello\n",
      "Detected Word: hello\n",
      "Detected Word: PLEASE\n",
      "Detected Word: PLEASE\n",
      "Detected Word: I/ME\n",
      "Detected Word: WANT\n",
      "Detected Word: WANT\n",
      "Detected Word: WANT\n",
      "Detected Word: GO\n",
      "Detected Word: WATER\n",
      "Detected Word: WATER\n",
      "Detected Word: WATER\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(r\"E:\\_clgproject\\new_project\\runs\\detect\\train2\\weights\\best.pt\")\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # Process detections and print words in real-time\n",
    "    detected_words = set()  # Store detected words in the current frame\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        class_index = int(box.cls)\n",
    "        word = model.names[class_index]  # Convert index to word using YOLO class names\n",
    "        detected_words.add(word)\n",
    "\n",
    "    # Print each detected word without cooldown\n",
    "    for word in detected_words:\n",
    "        print(f\"Detected Word: {word}\")\n",
    "\n",
    "    # Display annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('Word Detection', annotated_frame)\n",
    "\n",
    "    # Exit condition on 'q' key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: I/me\n",
      "Generated Sentence: I/me\n",
      "Generated Sentence: Want\n",
      "Generated Sentence: Want\n",
      "Generated Sentence: Water\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(r\"E:\\_clgproject\\new_project\\runs\\detect\\train2\\weights\\best.pt\")\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Initialize word tracking and cooldown\n",
    "word_counter = Counter()\n",
    "cooldown = 0\n",
    "\n",
    "def filter_and_generate_sentence(counter):\n",
    "    \"\"\"Generate a sentence from detected word frequencies.\"\"\"\n",
    "    words = [word for word, count in counter.items() if count > 1]  # Filter stable words\n",
    "    return \" \".join(words).capitalize() if words else None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    current_frame_words = []\n",
    "\n",
    "    # Detect words in the current frame\n",
    "    for box in results[0].boxes:\n",
    "        class_index = int(box.cls)\n",
    "        word = model.names[class_index].lower()\n",
    "        current_frame_words.append(word)\n",
    "\n",
    "    # Update word counter and clear words with low counts\n",
    "    word_counter.update(current_frame_words)\n",
    "\n",
    "    # Generate and print a sentence if cooldown allows\n",
    "    if cooldown <= 0:\n",
    "        sentence = filter_and_generate_sentence(word_counter)\n",
    "        if sentence:\n",
    "            print(f\"Generated Sentence: {sentence}\")\n",
    "            word_counter.clear()  # Clear after sentence generation\n",
    "            cooldown = 0  # Frame cooldown to prevent immediate sentence regeneration\n",
    "\n",
    "    # Display the annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('Word Detection and Sentence Formation', annotated_frame)\n",
    "\n",
    "    # Exit condition on 'q' key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    cooldown -= 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: Hello\n",
      "Generated Sentence: Hello\n",
      "Generated Sentence: Please\n",
      "Generated Sentence: I/me want\n",
      "Generated Sentence: Water\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(r\"E:\\_clgproject\\new_project\\runs\\detect\\train2\\weights\\best.pt\")\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Initialize word tracking and cooldown\n",
    "word_counter = Counter()\n",
    "no_action_frames = 0\n",
    "max_no_action_frames =10  # Reset sentence after 15 frames of no hand detection\n",
    "\n",
    "def filter_and_generate_sentence(counter):\n",
    "    \"\"\"Generate a sentence from detected word frequencies.\"\"\"\n",
    "    words = [word for word, count in counter.items() if count > 1]  # Filter stable words\n",
    "    return \" \".join(words).capitalize() if words else None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    current_frame_words = []\n",
    "\n",
    "    # Detect words in the current frame\n",
    "    for box in results[0].boxes:\n",
    "        class_index = int(box.cls)\n",
    "        word = model.names[class_index].lower()\n",
    "        current_frame_words.append(word)\n",
    "\n",
    "    # Check if hand actions are detected or not\n",
    "    if current_frame_words:\n",
    "        no_action_frames = 0  # Reset inactivity counter if hand action is detected\n",
    "        word_counter.update(current_frame_words)\n",
    "    else:\n",
    "        no_action_frames += 1  # Increment counter when no hand action is detected\n",
    "\n",
    "    # Generate and print a sentence after stable word detection or on inactivity reset\n",
    "    if no_action_frames >= max_no_action_frames or (len(word_counter) > 0 and len(current_frame_words) == 0):\n",
    "        sentence = filter_and_generate_sentence(word_counter)\n",
    "        if sentence:\n",
    "            print(f\"Generated Sentence: {sentence}\")\n",
    "            word_counter.clear()  # Clear word count to start the next sentence\n",
    "            no_action_frames = 0  # Reset inactivity counter after sentence generation\n",
    "\n",
    "    # Display the annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('Word Detection and Sentence Formation', annotated_frame)\n",
    "\n",
    "    # Exit condition on 'q' key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_ava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
